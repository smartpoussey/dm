import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from itertools import combinations
from collections import defaultdict
from mlxtend.frequent_patterns import fpgrowth, association_rules


def read_transactions_from_csv(filename):
    df = pd.read_csv(filename, header=None, dtype=str)
    transactions = [set(df.iloc[i].dropna().str.strip()) for i in range(len(df))]
    return transactions

"""
def read_transactions_from_csv(filename):
    df = pd.read_csv(filename, dtype=str).fillna("")
    transactions = df.apply(lambda row: [item.strip() for item in row if item.strip()], axis=1).tolist()
    return transactions
"""

def has_infrequent_subset(candidate, frequent_itemsets):
    for subset in combinations(candidate, len(candidate) - 1):
        if frozenset(subset) not in frequent_itemsets:
            return False
    return True

def get_frequent_itemsets(transactions, min_support):
    item_counts = defaultdict(int)
    for transaction in transactions:
        for item in transaction:
            item_counts[frozenset([item])] += 1

    min_support_count = len(transactions) * min_support

    frequent_itemsets = {}

    for itemset, count in item_counts.items():
        if count >= min_support_count:
            frequent_itemsets[itemset] = count

    k = 2
    while True:
        candidates = set()

        frequent_items = list(frequent_itemsets.keys())

        for i in range(len(frequent_items)):
            for j in range(i + 1, len(frequent_items)):
                items1 = set(frequent_items[i])
                items2 = set(frequent_items[j])
                union = items1.union(items2)
                if len(union) == k and has_infrequent_subset(union, frequent_itemsets):
                    candidates.add(frozenset(union))

        if not candidates:
            break

        candidate_counts = defaultdict(int)
        for transaction in transactions:
            for candidate in candidates:
                if candidate.issubset(transaction):
                    candidate_counts[candidate] += 1

        new_frequent = {}
        for itemset, count in candidate_counts.items():
            if count >= min_support_count:
                new_frequent[itemset] = count

        if not new_frequent:
            break

        frequent_itemsets.update(new_frequent)
        k += 1

    return frequent_itemsets


def generate_association_rules(frequent_itemsets, transactions, min_confidence):
    rules = []
    total_transactions = len(transactions)

    for itemset, support in frequent_itemsets.items():
        if len(itemset) < 2:
            continue

        for i in range(1, len(itemset)):
            for antecedent in combinations(itemset, i):
                antecedent = frozenset(antecedent)
                consequent = frozenset(itemset - antecedent)
                antecedent_support = sum(1 for t in transactions if antecedent.issubset(t))
                confidence = support / antecedent_support

                if confidence >= min_confidence:
                    support_percentage = support / total_transactions
                    rules.append((set(antecedent), set(consequent), confidence, support_percentage))

    rules.sort(key=sort_by_confidence, reverse=True)
    return rules

def sort_by_confidence(rule):
    return rule[2]

def print_rules(rules):
    for antecedent, consequent, confidence, support in rules:
        print(f"{antecedent} => {consequent}")
        print(f"Confidence: {confidence:.2%}")
        print(f"Support: {support:.2%}")
        print("-" * 50)

def convert_to_dataframe(transactions):
    unique_items = sorted(set(item for transaction in transactions for item in transaction))
    df = pd.DataFrame([{item: (item in transaction) for item in unique_items} for transaction in transactions])
    return df

filename = "data.csv"
min_support = 0.2
min_confidence = 0.5

transactions = read_transactions_from_csv(filename)
frequent_itemsets = get_frequent_itemsets(transactions, min_support)
print("Frequent Itemsets:")
for itemset, support in frequent_itemsets.items():
    print(f"{itemset} (Support: {support})")

print("\nAssociation Rules:")
rules = generate_association_rules(frequent_itemsets, transactions, min_confidence)
print_rules(rules)


df = convert_to_dataframe(transactions)

# Apply FP-Growth algorithm
frequent_itemsets = fpgrowth(df, min_support=min_support, use_colnames=True)

rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)

print("\nFrequent Itemsets:")
print(frequent_itemsets)

print("\nAssociation Rules:")
print(rules[['antecedents', 'consequents', 'support', 'confidence']])


# Top Frequent Itemsets - Bar Chart
plt.figure(figsize=(10, 5))
frequent_itemsets.nlargest(10, 'support').plot(kind="bar", x="itemsets", y="support", legend=False, color="skyblue")
plt.xlabel("Itemsets")
plt.ylabel("Support")
plt.title("Top 10 Frequent Itemsets")
plt.xticks(rotation=45, ha='right')
plt.show()
